# -*- coding: utf-8 -*-
"""fake_news_detection.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W-Rz84eZevO1YgtBCHmeKqqQv0u8ZzTT
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import pickle
import re
from datetime import datetime

# Uploading Data and Concatenation
def load_and_prepare_data():
    fake_df = pd.read_csv('Fake.csv')
    true_df = pd.read_csv('True.csv')

    fake_df['label'] = 0  # Fake News
    true_df['label'] = 1  # True News

    df = pd.concat([fake_df, true_df], ignore_index=True)

    df = df.sample(frac=1).reset_index(drop=True)

    return df

# Text Cleaning
def clean_text(text):
    if pd.isna(text):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Feature engineering
def prepare_features(df):
    df['title'] = df['title'].fillna('')
    df['text'] = df['text'].fillna('')
    df['subject'] = df['subject'].fillna('')

    df['title_clean'] = df['title'].apply(clean_text)
    df['text_clean'] = df['text'].apply(clean_text)

    df['combined_text'] = df['title_clean'] + ' ' + df['text_clean']

    df['title_length'] = df['title'].str.len()
    df['text_length'] = df['text'].str.len()
    df['title_word_count'] = df['title'].str.split().str.len()
    df['text_word_count'] = df['text'].str.split().str.len()

    df['title_upper_ratio'] = df['title'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) / len(str(x)) if len(str(x)) > 0 else 0)

    df['exclamation_count'] = df['combined_text'].str.count('!')

    return df

# Model Training
def train_models(df):
    # Features and target
    X_text = df['combined_text']
    y = df['label']

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X_text, y, test_size=0.2, random_state=42, stratify=y
    )

    # TF-IDF Vectorization
    vectorizer = TfidfVectorizer(
        max_features=10000,
        stop_words='english',
        ngram_range=(1, 2),  # Unigram ve bigram
        min_df=2,
        max_df=0.95
    )

    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    # Model Training
    models = {
        'Naive Bayes': MultinomialNB(alpha=0.1),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
    }

    results = {}
    trained_models = {}

    for name, model in models.items():
        print(f"\n{name} is being trained...")
        model.fit(X_train_tfidf, y_train)
        y_pred = model.predict(X_test_tfidf)

        accuracy = accuracy_score(y_test, y_pred)
        results[name] = accuracy
        trained_models[name] = model

        print(f"{name} Accuracy: {accuracy:.4f}")
        print(f"{name} Classification Report:")
        print(classification_report(y_test, y_pred))

    # The Best Model
    best_model_name = max(results, key=results.get)
    best_model = trained_models[best_model_name]

    print(f"\nEn iyi model: {best_model_name} (Accuracy: {results[best_model_name]:.4f})")

    with open('best_model.pkl', 'wb') as f:
        pickle.dump(best_model, f)

    with open('vectorizer.pkl', 'wb') as f:
        pickle.dump(vectorizer, f)

    with open('model_info.pkl', 'wb') as f:
        pickle.dump({'name': best_model_name, 'accuracy': results[best_model_name]}, f)

    return best_model, vectorizer, best_model_name

# Main Function
def main():
    print("Fake News Detection Model Traininf")
    print("=" * 50)

    print("Data is being uploaded...")
    df = load_and_prepare_data()

    print(f"Total data number: {len(df)}")
    print(f"Fake news: {sum(df['label'] == 0)}")
    print(f"True news: {sum(df['label'] == 1)}")

    # Feature engineering
    print("\Feature engineering...")
    df = prepare_features(df)

    print("\nModels are being trained...")
    best_model, vectorizer, model_name = train_models(df)

    print(f"\Completed! The Best Model: {model_name}")
    print("Saved!:")
    print("- best_model.pkl")
    print("- vectorizer.pkl")
    print("- model_info.pkl")

if __name__ == "__main__":
    main()